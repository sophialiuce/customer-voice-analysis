{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt, re\n",
    "\n",
    "def main(argv):\n",
    "    inputfile = ''\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv,\"i:\")\n",
    "        # print(opts,args)\n",
    "    except getopt.GetoptError:\n",
    "        print('LanguageModeling.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    \n",
    "    for opt, arg in opts:\n",
    "        if opt == \"-i\":\n",
    "            inputfile = arg\n",
    "    \n",
    "    if len(inputfile)==0:\n",
    "        print('usage: LanguageModeling.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    print('Input BRAND is ', inputfile)\n",
    "    return inputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND      = 'HAIRCARE'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BRAND      = main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * # Quick access to NLP functionality\n",
    "from fastai.callbacks import EarlyStoppingCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (from saved verbatim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>verbatum</th>\n",
       "      <th>sentiment_binary</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>retailer</th>\n",
       "      <th>website</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "      <td>Head And Shoulders Smooth &amp; Silky Dandruff Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5/2/2018</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.walmart.com/ip/Head-and-Shoulders-...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The thing I always remember about Head &amp; Shoul...</td>\n",
       "      <td>Head And Shoulders Green Apple Anti-Dandruff S...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My teenaged daughter has been using Head &amp; Sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>9/29/2017</td>\n",
       "      <td>AMZ</td>\n",
       "      <td>https://www.amazon.com/Head-Shoulders-Anti-Dan...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My long, thick, wavy, hair is frequently abuse...</td>\n",
       "      <td>Dove Dermacare Scalp Anti-Dandruff Shampoo Inv...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>To my surprise, Dove DermaCare Scalp Invigorat...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>https://www.walmart.com/ip/Dove-Dermacare-Scal...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From their body sprays, to their deodorant, so...</td>\n",
       "      <td>Dove Dermacare Scalp Anti-Dandruff Shampoo Dry...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I let my boyfriend try this product. He loves ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.walmart.com/ip/Dove-Dermacare-Scal...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "      <td>Head And Shoulders Dry Scalp Care, Almond Oil,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/14/2016</td>\n",
       "      <td>AMZ</td>\n",
       "      <td>https://www.amazon.com/Head-Shoulders-Almond-D...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             snippet  \\\n",
       "0  This shampoo sprays crazy good and it has save...   \n",
       "1  The thing I always remember about Head & Shoul...   \n",
       "2  My long, thick, wavy, hair is frequently abuse...   \n",
       "3  From their body sprays, to their deodorant, so...   \n",
       "4  Its conveniently packaged, but if this bottle ...   \n",
       "\n",
       "                                             product rating  \\\n",
       "0  Head And Shoulders Smooth & Silky Dandruff Sha...    5.0   \n",
       "1  Head And Shoulders Green Apple Anti-Dandruff S...    5.0   \n",
       "2  Dove Dermacare Scalp Anti-Dandruff Shampoo Inv...    4.0   \n",
       "3  Dove Dermacare Scalp Anti-Dandruff Shampoo Dry...    5.0   \n",
       "4  Head And Shoulders Dry Scalp Care, Almond Oil,...    4.0   \n",
       "\n",
       "                                            verbatum sentiment_binary  \\\n",
       "0  This shampoo sprays crazy good and it has save...                1   \n",
       "1  My teenaged daughter has been using Head & Sho...                1   \n",
       "2  To my surprise, Dove DermaCare Scalp Invigorat...                1   \n",
       "3  I let my boyfriend try this product. He loves ...                1   \n",
       "4  Its conveniently packaged, but if this bottle ...                1   \n",
       "\n",
       "  sentiment       date retailer  \\\n",
       "0  Positive   5/2/2018        -   \n",
       "1  Positive  9/29/2017      AMZ   \n",
       "2  Positive  1/27/2017  WALMART   \n",
       "3  Positive  1/27/2017        -   \n",
       "4  Positive  1/14/2016      AMZ   \n",
       "\n",
       "                                             website              topic  \n",
       "0  https://www.walmart.com/ip/Head-and-Shoulders-...  Spray Application  \n",
       "1  https://www.amazon.com/Head-Shoulders-Anti-Dan...  Spray Application  \n",
       "2  https://www.walmart.com/ip/Dove-Dermacare-Scal...  Spray Application  \n",
       "3  https://www.walmart.com/ip/Dove-Dermacare-Scal...  Spray Application  \n",
       "4  https://www.amazon.com/Head-Shoulders-Almond-D...  Spray Application  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/sample_data.csv', dtype={'verbatum':object})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the full verbatum; remove duplicates and too short verbatum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full verbatum and enforce\n",
    "df = df[['verbatum']].rename(columns = {'verbatum':'text'})\n",
    "\n",
    "# enforce format\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# remove short comments (keep 2nd percentile and higher lenghts)\n",
    "thresh = df['text'].apply(len).quantile(0.02)\n",
    "\n",
    "df = df.loc[df['text'].apply(lambda x: len(x)>=thresh)].\\\n",
    "    drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My teenaged daughter has been using Head &amp; Sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To my surprise, Dove DermaCare Scalp Invigorat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I let my boyfriend try this product. He loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  This shampoo sprays crazy good and it has save...\n",
       "1  My teenaged daughter has been using Head & Sho...\n",
       "2  To my surprise, Dove DermaCare Scalp Invigorat...\n",
       "3  I let my boyfriend try this product. He loves ...\n",
       "4  Its conveniently packaged, but if this bottle ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Tokenization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setup stop words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "for word in STOP_WORDS:\n",
    "    for w in (word, word[0].capitalize(), word.upper()):\n",
    "        lex = nlp.vocab[w]\n",
    "        lex.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)-set(['!','?'])\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess(doc, tags=['NOUN', 'ADJ','VERB','ADV']):\n",
    "    # make entire text lower case\n",
    "    doc = doc.lower()    \n",
    "    \n",
    "    # replace \"n't\" with \" not\" & remove unwanted characters, numbers and symbols\n",
    "    doc = doc.replace(\"n\\'t\", \" not\").replace(\"[^a-zA-Z#]\", \" \")\n",
    "       \n",
    "    # remove stop words\n",
    "    # doc = \" \".join([i for i in doc.split() if i not in stop])\n",
    "    \n",
    "    # remove short words (length < 3)\n",
    "    # doc = \" \".join([r for r in doc.split() if len(r)>2])\n",
    "    \n",
    "    # remove punctuation\n",
    "    # doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "    \n",
    "    # lemmatization\n",
    "    # doc = \" \".join([token.lemma_ for token in nlp(doc)])# if token.pos_ in tags])\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-Tokenization\n"
     ]
    }
   ],
   "source": [
    "# removes stop words, short words, and punctuation; lowercase and lemmatize all\n",
    "print(' Pre-Tokenization')\n",
    "df['text']        = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "\n",
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.random.rand(len(df)) < .10\n",
    "df_train = df[ seq]\n",
    "df_test  = df[~seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter for both language and classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "moms = (0.8,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `DataBunch` for each of the language model and the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path, train_df=df_train, valid_df=df_test, text_cols='text')#,\\\n",
    "#                                  tokenizer=Tokenizer(BaseTokenizer))\n",
    "\n",
    "# callbacks\n",
    "callback_fns = [partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.01, patience=10),\\\n",
    "                partial(SaveModelCallback, monitor='accuracy', every='improvement', name='lm_{:}.mdl'.format(BRAND))]\n",
    "\n",
    "# We'll fine-tune the language model. [fast.ai](http://www.fast.ai/) has a \n",
    "# pre-trained English model available that we can download, we jsut have to specify it like this:\n",
    "learner = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, \\\n",
    "    callback_fns=callback_fns)\n",
    "\n",
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(8, slice(1e-2), moms=moms)\n",
    "\n",
    "# Save our language model's encoder:\n",
    "learner.save_encoder('encoder_{:}'.format(BRAND))\n",
    "\n",
    "# Save vocab\n",
    "vocab = data_lm.train_ds.vocab\n",
    "with open('./models/vocab_{:}.pkl'.format(BRAND), 'wb') as handle:\n",
    "    pickle.dump(vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(8, slice(1e-2), moms=moms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('languagemodel_{:}'.format(BRAND))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save encoder matrix in array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model\n",
    "m.eval()\n",
    "layers = list(m.children())\n",
    "\n",
    "emb_mtx = layers[0].encoder.weight.cpu().data.numpy()\n",
    "\n",
    "with open('./models/embedding_mtx_{:}.pkl'.format(BRAND), 'wb') as handle:\n",
    "    pickle.dump(emb_mtx, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the product leave -pron- with itch scalp . just like that . i 'm happy with the product so i do feel like it works on the\n"
     ]
    }
   ],
   "source": [
    "if True: print(learner.predict(\"the product leave -pron- with itch scalp\", n_words=20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
