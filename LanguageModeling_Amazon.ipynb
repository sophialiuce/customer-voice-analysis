{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * # Quick access to NLP functionality\n",
    "from fastai.callbacks import EarlyStoppingCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND = 'Health_and_Personal_Care'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (from saved verbatim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "      <td>01 5, 2011</td>\n",
       "      <td>ALC5GH8CAMAI7</td>\n",
       "      <td>AnnN</td>\n",
       "      <td>Handy little gadget</td>\n",
       "      <td>1294185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "      <td>02 18, 2012</td>\n",
       "      <td>AHKSURW85PJUE</td>\n",
       "      <td>AZ buyer \"AZ buyer\"</td>\n",
       "      <td>Small &amp; may need to encourage battery</td>\n",
       "      <td>1329523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[75, 77]</td>\n",
       "      <td>4</td>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "      <td>06 8, 2010</td>\n",
       "      <td>A38RMU1Y5TDP9</td>\n",
       "      <td>Bob Tobias \"Robert Tobias\"</td>\n",
       "      <td>Very good but not great</td>\n",
       "      <td>1275955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[56, 60]</td>\n",
       "      <td>4</td>\n",
       "      <td>Love the Great point light pocket magnifier!  ...</td>\n",
       "      <td>02 8, 2008</td>\n",
       "      <td>A1XZUG7DFXXOS4</td>\n",
       "      <td>Cat lover</td>\n",
       "      <td>great addition to your purse</td>\n",
       "      <td>1202428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is very nice. You pull out on the magnifi...</td>\n",
       "      <td>08 16, 2011</td>\n",
       "      <td>A1MS3M7M7AM13X</td>\n",
       "      <td>Cricketoes</td>\n",
       "      <td>Very nice and convenient.</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin   helpful  overall  \\\n",
       "0  159985130X    [1, 1]        5   \n",
       "1  159985130X    [1, 1]        4   \n",
       "2  159985130X  [75, 77]        4   \n",
       "3  159985130X  [56, 60]        4   \n",
       "4  159985130X    [1, 1]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This is a great little gadget to have around. ...   01 5, 2011   \n",
       "1  I would recommend this for a travel magnifier ...  02 18, 2012   \n",
       "2  What I liked was the quality of the lens and t...   06 8, 2010   \n",
       "3  Love the Great point light pocket magnifier!  ...   02 8, 2008   \n",
       "4  This is very nice. You pull out on the magnifi...  08 16, 2011   \n",
       "\n",
       "       reviewerID                reviewerName  \\\n",
       "0   ALC5GH8CAMAI7                        AnnN   \n",
       "1   AHKSURW85PJUE         AZ buyer \"AZ buyer\"   \n",
       "2   A38RMU1Y5TDP9  Bob Tobias \"Robert Tobias\"   \n",
       "3  A1XZUG7DFXXOS4                   Cat lover   \n",
       "4  A1MS3M7M7AM13X                  Cricketoes   \n",
       "\n",
       "                                 summary  unixReviewTime  \n",
       "0                    Handy little gadget      1294185600  \n",
       "1  Small & may need to encourage battery      1329523200  \n",
       "2                Very good but not great      1275955200  \n",
       "3           great addition to your purse      1202428800  \n",
       "4              Very nice and convenient.      1313452800  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"./data/reviews_data.json\", lines=True) #\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the text snippets and associated topic; remove duplicates and too short verbatum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep snippets\n",
    "df = df[['reviewText']].rename(columns = {'reviewText':'text'})\n",
    "\n",
    "# enforce format\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# remove short comments (keep 2nd percentile and higher lenghts)\n",
    "thresh = df['text'].apply(len).quantile(0.02)\n",
    "\n",
    "df = df.loc[df['text'].apply(lambda x: len(x)>=thresh)].\\\n",
    "    drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love the Great point light pocket magnifier!  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is very nice. You pull out on the magnifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  This is a great little gadget to have around. ...\n",
       "1  I would recommend this for a travel magnifier ...\n",
       "2  What I liked was the quality of the lens and t...\n",
       "3  Love the Great point light pocket magnifier!  ...\n",
       "4  This is very nice. You pull out on the magnifi..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Tokenization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setup stop words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "for word in STOP_WORDS:\n",
    "    for w in (word, word[0].capitalize(), word.upper()):\n",
    "        lex = nlp.vocab[w]\n",
    "        lex.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)-set(['!','?'])\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess(doc, tags=['NOUN', 'ADJ','VERB','ADV']):\n",
    "    # make entire text lower case\n",
    "    # doc = doc.lower()    \n",
    "    \n",
    "    # replace \"n't\" with \" not\" & remove unwanted characters, numbers and symbols\n",
    "    doc = doc.replace(\"n\\'t\", \" not\")#.replace(\"[^a-zA-Z#]\", \" \")\n",
    "       \n",
    "    # remove stop words\n",
    "    # doc = \" \".join([i for i in doc.split() if i not in stop])\n",
    "    \n",
    "    # remove short words (length < 3)\n",
    "    # doc = \" \".join([r for r in doc.split() if len(r)>2])\n",
    "    \n",
    "    # remove punctuation\n",
    "    # doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "    \n",
    "    # lemmatization\n",
    "    # doc = \" \".join([token.lemma_ for token in nlp(doc)])# if token.pos_ in tags])\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-Tokenization\n"
     ]
    }
   ],
   "source": [
    "# removes stop words, short words, and punctuation; lowercase and lemmatize all\n",
    "print(' Pre-Tokenization')\n",
    "df['text']        = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "\n",
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.random.rand(len(df)) < .10\n",
    "df_train = df[ seq]\n",
    "df_test  = df[~seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter for both language and classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "moms = (0.8,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `DataBunch` for each of the language model and the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path, train_df=df_train, valid_df=df_test, text_cols='text')\n",
    "\n",
    "# callbacks\n",
    "callback_fns = [partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.01, patience=10),\\\n",
    "                partial(SaveModelCallback, monitor='accuracy', every='improvement', name='lm_{:}.mdl'.format(BRAND))]\n",
    "\n",
    "# We'll fine-tune the language model. [fast.ai](http://www.fast.ai/) has a \n",
    "# pre-trained English model available that we can download, we jsut have to specify it like this:\n",
    "learner = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, \\\n",
    "    callback_fns=callback_fns)\n",
    "\n",
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(8, slice(1e-2), moms=moms)\n",
    "\n",
    "# learner.unfreeze()\n",
    "# learner.fit(8, slice(1e-2))\n",
    "\n",
    "# Save our language model's encoder:\n",
    "learner.save_encoder('encoder_{:}'.format(BRAND))\n",
    "\n",
    "# Save vocab\n",
    "vocab = data_lm.train_ds.vocab\n",
    "# with open('../models/vocab_{:}.pkl'.format(BRAND), 'wb') as handle:\n",
    "#     pickle.dump(vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(8, slice(1e-2), moms=moms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.save('languagemodel_{:}'.format(BRAND))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save encoder matrix in array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = learner.model\n",
    "# m.eval()\n",
    "# layers = list(m.children())\n",
    "\n",
    "# emb_mtx = layers[0].encoder.weight.cpu().data.numpy()\n",
    "\n",
    "# with open('../models/embedding_mtx_{:}.pickle'.format(BRAND), 'wb') as handle:\n",
    "#     pickle.dump(emb_mtx, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: learner.predict(\"the product leave -pron- with itch scalp\", n_words=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
