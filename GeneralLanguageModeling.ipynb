{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt, re\n",
    "\n",
    "def main(argv):\n",
    "    inputfile = ''\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv,\"i:\")\n",
    "        # print(opts,args)\n",
    "    except getopt.GetoptError:\n",
    "        print('LanguageModeling.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    \n",
    "    for opt, arg in opts:\n",
    "        if opt == \"-i\":\n",
    "            inputfile = arg\n",
    "    \n",
    "    if len(inputfile)==0:\n",
    "        print('usage: LanguageModeling.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    print('Input BRAND is ', inputfile)\n",
    "    return inputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND      = 'HAIRCARE'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BRAND      = main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * # Quick access to NLP functionality\n",
    "from fastai.callbacks import EarlyStoppingCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (from saved verbatim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>verbatum</th>\n",
       "      <th>sentiment_binary</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>retailer</th>\n",
       "      <th>website</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "      <td>Head And Shoulders Smooth &amp; Silky Dandruff Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5/2/2018</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.walmart.com/ip/Head-and-Shoulders-...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The thing I always remember about Head &amp; Shoul...</td>\n",
       "      <td>Head And Shoulders Green Apple Anti-Dandruff S...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My teenaged daughter has been using Head &amp; Sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>9/29/2017</td>\n",
       "      <td>AMZ</td>\n",
       "      <td>https://www.amazon.com/Head-Shoulders-Anti-Dan...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My long, thick, wavy, hair is frequently abuse...</td>\n",
       "      <td>Dove Dermacare Scalp Anti-Dandruff Shampoo Inv...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>To my surprise, Dove DermaCare Scalp Invigorat...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>https://www.walmart.com/ip/Dove-Dermacare-Scal...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From their body sprays, to their deodorant, so...</td>\n",
       "      <td>Dove Dermacare Scalp Anti-Dandruff Shampoo Dry...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I let my boyfriend try this product. He loves ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.walmart.com/ip/Dove-Dermacare-Scal...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "      <td>Head And Shoulders Dry Scalp Care, Almond Oil,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/14/2016</td>\n",
       "      <td>AMZ</td>\n",
       "      <td>https://www.amazon.com/Head-Shoulders-Almond-D...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             snippet  \\\n",
       "0  This shampoo sprays crazy good and it has save...   \n",
       "1  The thing I always remember about Head & Shoul...   \n",
       "2  My long, thick, wavy, hair is frequently abuse...   \n",
       "3  From their body sprays, to their deodorant, so...   \n",
       "4  Its conveniently packaged, but if this bottle ...   \n",
       "\n",
       "                                             product rating  \\\n",
       "0  Head And Shoulders Smooth & Silky Dandruff Sha...    5.0   \n",
       "1  Head And Shoulders Green Apple Anti-Dandruff S...    5.0   \n",
       "2  Dove Dermacare Scalp Anti-Dandruff Shampoo Inv...    4.0   \n",
       "3  Dove Dermacare Scalp Anti-Dandruff Shampoo Dry...    5.0   \n",
       "4  Head And Shoulders Dry Scalp Care, Almond Oil,...    4.0   \n",
       "\n",
       "                                            verbatum sentiment_binary  \\\n",
       "0  This shampoo sprays crazy good and it has save...                1   \n",
       "1  My teenaged daughter has been using Head & Sho...                1   \n",
       "2  To my surprise, Dove DermaCare Scalp Invigorat...                1   \n",
       "3  I let my boyfriend try this product. He loves ...                1   \n",
       "4  Its conveniently packaged, but if this bottle ...                1   \n",
       "\n",
       "  sentiment       date retailer  \\\n",
       "0  Positive   5/2/2018        -   \n",
       "1  Positive  9/29/2017      AMZ   \n",
       "2  Positive  1/27/2017  WALMART   \n",
       "3  Positive  1/27/2017        -   \n",
       "4  Positive  1/14/2016      AMZ   \n",
       "\n",
       "                                             website              topic  \n",
       "0  https://www.walmart.com/ip/Head-and-Shoulders-...  Spray Application  \n",
       "1  https://www.amazon.com/Head-Shoulders-Anti-Dan...  Spray Application  \n",
       "2  https://www.walmart.com/ip/Dove-Dermacare-Scal...  Spray Application  \n",
       "3  https://www.walmart.com/ip/Dove-Dermacare-Scal...  Spray Application  \n",
       "4  https://www.amazon.com/Head-Shoulders-Almond-D...  Spray Application  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/sample_data.csv', dtype={'verbatum':object})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the text snippets and associated topic; remove duplicates and too short verbatum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full verbatum and enforce\n",
    "df = df[['verbatum']].rename(columns = {'verbatum':'text'})\n",
    "\n",
    "# enforce format\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# remove short comments (keep 2nd percentile and higher lenghts)\n",
    "thresh = df['text'].apply(len).quantile(0.02)\n",
    "\n",
    "df = df.loc[df['text'].apply(lambda x: len(x)>=thresh)].\\\n",
    "    drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The thing I always remember about Head &amp; Shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My long, thick, wavy, hair is frequently abuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From their body sprays, to their deodorant, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  This shampoo sprays crazy good and it has save...\n",
       "1  The thing I always remember about Head & Shoul...\n",
       "2  My long, thick, wavy, hair is frequently abuse...\n",
       "3  From their body sprays, to their deodorant, so...\n",
       "4  Its conveniently packaged, but if this bottle ..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Tokenization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setup stop words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "for word in STOP_WORDS:\n",
    "    for w in (word, word[0].capitalize(), word.upper()):\n",
    "        lex = nlp.vocab[w]\n",
    "        lex.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)-set(['!','?'])\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess(doc, tags=['NOUN', 'ADJ','VERB','ADV']):\n",
    "    # make entire text lower case\n",
    "    #doc = doc.lower()    \n",
    "    \n",
    "    # replace \"n't\" with \" not\" & remove unwanted characters, numbers and symbols\n",
    "    doc = doc.replace(\"n\\'t\", \" not\").replace(\"[^a-zA-Z#]\", \" \")\n",
    "       \n",
    "    # remove stop words\n",
    "    # doc = \" \".join([i for i in doc.split() if i not in stop])\n",
    "    \n",
    "    # remove short words (length < 3)\n",
    "    # doc = \" \".join([r for r in doc.split() if len(r)>2])\n",
    "    \n",
    "    # remove punctuation\n",
    "    # doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "    \n",
    "    # lemmatization\n",
    "    #doc = \" \".join([token.lemma_ for token in nlp(doc)])# if token.pos_ in tags])\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-Tokenization\n"
     ]
    }
   ],
   "source": [
    "# removes stop words, short words, and punctuation; lowercase and lemmatize all\n",
    "print(' Pre-Tokenization')\n",
    "df['text']        = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "\n",
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.random.rand(len(df)) < .10\n",
    "df_train = df[ seq]\n",
    "df_test  = df[~seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter for both language and classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "moms = (0.8,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `DataBunch` for each of the language model and the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:40 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>5.814195</th>\n",
       "    <th>4.557719</th>\n",
       "    <th>0.215476</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>4.982989</th>\n",
       "    <th>3.446336</th>\n",
       "    <th>0.308865</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>4.395122</th>\n",
       "    <th>3.140041</th>\n",
       "    <th>0.338324</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>4.023887</th>\n",
       "    <th>3.034026</th>\n",
       "    <th>0.339254</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>3.762325</th>\n",
       "    <th>2.979870</th>\n",
       "    <th>0.345013</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>3.576139</th>\n",
       "    <th>2.956544</th>\n",
       "    <th>0.346706</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>3.441876</th>\n",
       "    <th>2.945744</th>\n",
       "    <th>0.350865</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>3.336954</th>\n",
       "    <th>2.945102</th>\n",
       "    <th>0.347729</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path, train_df=df_train, valid_df=df_test, text_cols='text')#,\\\n",
    "#                                  tokenizer=Tokenizer(BaseTokenizer))\n",
    "\n",
    "# callbacks\n",
    "callback_fns = [partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.01, patience=10),\\\n",
    "                partial(SaveModelCallback, monitor='accuracy', every='improvement', name='lm_{:}.mdl'.format(BRAND))]\n",
    "\n",
    "# We'll fine-tune the language model. [fast.ai](http://www.fast.ai/) has a \n",
    "# pre-trained English model available that we can download, we jsut have to specify it like this:\n",
    "learner = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, \\\n",
    "    callback_fns=callback_fns)\n",
    "\n",
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(8, slice(1e-2), moms=moms)\n",
    "\n",
    "# learner.unfreeze()\n",
    "# learner.fit(8, slice(1e-2))\n",
    "\n",
    "# Save our language model's encoder:\n",
    "# learner.save_encoder('encoder_{:}'.format(BRAND))\n",
    "\n",
    "# Save vocab\n",
    "# vocab = data_lm.train_ds.vocab\n",
    "# with open('./models/vocab_{:}.pkl'.format(BRAND), 'wb') as handle:\n",
    "#     pickle.dump(vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:38 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.017501</th>\n",
       "    <th>2.932412</th>\n",
       "    <th>0.352876</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.020961</th>\n",
       "    <th>2.923144</th>\n",
       "    <th>0.356218</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>2.988355</th>\n",
       "    <th>2.890624</th>\n",
       "    <th>0.361425</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>2.940469</th>\n",
       "    <th>2.880912</th>\n",
       "    <th>0.356464</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>2.896958</th>\n",
       "    <th>2.866887</th>\n",
       "    <th>0.363664</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>2.844975</th>\n",
       "    <th>2.856881</th>\n",
       "    <th>0.365943</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>2.803013</th>\n",
       "    <th>2.857414</th>\n",
       "    <th>0.364820</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>2.768991</th>\n",
       "    <th>2.856935</th>\n",
       "    <th>0.365050</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(8, slice(1e-2), moms=moms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.save('languagemodel_{:}'.format(BRAND))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save encoder matrix in array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = learner.model\n",
    "# m.eval()\n",
    "# layers = list(m.children())\n",
    "\n",
    "# emb_mtx = layers[0].encoder.weight.cpu().data.numpy()\n",
    "\n",
    "# with open('./models/embedding_mtx_{:}.pickle'.format(BRAND), 'wb') as handle:\n",
    "#     pickle.dump(emb_mtx, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I smells ? xxbos xxmaj it work very well the whole day . xxbos xxmaj it does not leave your hair'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict(\"How do I\", n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This product left me with itchy scalp . xxbos xxmaj after using this , i was hesitant to try to help keep my dandruff itchy ... but'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict(\"This product left me with itchy scalp\", n_words=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
