{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt, re\n",
    "\n",
    "def main(argv):\n",
    "    inputfile = ''\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv,\"i:\")\n",
    "        # print(opts,args)\n",
    "    except getopt.GetoptError:\n",
    "        print('TopicClassifier_Inference.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    \n",
    "    for opt, arg in opts:\n",
    "        if opt == \"-i\":\n",
    "            inputfile = arg\n",
    "    \n",
    "    if len(inputfile)==0:\n",
    "        print('usage: TopicClassifier_Inference.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    print('Input BRAND is ', inputfile)\n",
    "    return inputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND      = 'HEAD & SHOULDERS'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BRAND      = main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * # Quick access to NLP functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (from saved verbatim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTACT_DATE</th>\n",
       "      <th>CONTACT_VERBATIM</th>\n",
       "      <th>CONTACT_VERBATIM_NOTES</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>PRODUCT_PATH</th>\n",
       "      <th>COMMENT_CATEGORY</th>\n",
       "      <th>COMMENT_SUBCATEGORY</th>\n",
       "      <th>COMMENT_DESCRIPTION</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_SECTOR</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>FULL_CONTACT_VERBATIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63.0</th>\n",
       "      <td>2018-05-08 00:00:00</td>\n",
       "      <td>Hi, I recently purchased the big bottles of yo...</td>\n",
       "      <td></td>\n",
       "      <td>Head &amp; Shoulders Shampoo</td>\n",
       "      <td>Head &amp; Shoulders/Shampoo</td>\n",
       "      <td>Product Quality Complaint</td>\n",
       "      <td>Dissatisfied with performance</td>\n",
       "      <td>Results; did not condition, moisturize as expe...</td>\n",
       "      <td>Beauty Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>HEAD &amp; SHOULDERS</td>\n",
       "      <td>Hi, I recently purchased the big bottles of yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64.0</th>\n",
       "      <td>2018-05-16 00:00:00</td>\n",
       "      <td>I have been using head and shoulders classic c...</td>\n",
       "      <td></td>\n",
       "      <td>Head &amp; Shoulders Shampoo FreshClean Classic Clean</td>\n",
       "      <td>Head &amp; Shoulders/Shampoo/Fresh &amp; Clean/Classic...</td>\n",
       "      <td>Product Quality Complaint</td>\n",
       "      <td>Sensory attributes</td>\n",
       "      <td>Smell, scent, aroma, odor</td>\n",
       "      <td>Beauty Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>HEAD &amp; SHOULDERS</td>\n",
       "      <td>I have been using head and shoulders classic c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>2018-05-30 00:00:00</td>\n",
       "      <td>I've used Head &amp; Shoulders for years, and for ...</td>\n",
       "      <td>question whether anything in the product is co...</td>\n",
       "      <td>Head &amp; Shoulders Shampoo Base GreenApple AntiD...</td>\n",
       "      <td>Head &amp; Shoulders/Shampoo/Base/Green Apple/Anti...</td>\n",
       "      <td>Product Quality Complaint</td>\n",
       "      <td>Sensory attributes</td>\n",
       "      <td>Smell, scent, aroma, odor</td>\n",
       "      <td>Beauty Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>HEAD &amp; SHOULDERS</td>\n",
       "      <td>I've used Head &amp; Shoulders for years, and for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67.0</th>\n",
       "      <td>2018-05-30 00:00:00</td>\n",
       "      <td>I've used Head &amp; Shoulders for years, and for ...</td>\n",
       "      <td>question whether anything in the product is co...</td>\n",
       "      <td>Head &amp; Shoulders Shampoo Base Apple ADShamCond...</td>\n",
       "      <td>Head &amp; Shoulders/Shampoo/Base/Apple/AntiDandru...</td>\n",
       "      <td>Product Quality Complaint</td>\n",
       "      <td>Sensory attributes</td>\n",
       "      <td>Smell, scent, aroma, odor</td>\n",
       "      <td>Beauty Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>HEAD &amp; SHOULDERS</td>\n",
       "      <td>I've used Head &amp; Shoulders for years, and for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224.0</th>\n",
       "      <td>2018-05-17 00:00:00</td>\n",
       "      <td>Did you change the making of or fragrance of y...</td>\n",
       "      <td>ant to stop using it but I honestly can’t stan...</td>\n",
       "      <td>Head &amp; Shoulders Shampoo</td>\n",
       "      <td>Head &amp; Shoulders/Shampoo</td>\n",
       "      <td>Product Quality Complaint</td>\n",
       "      <td>Sensory attributes</td>\n",
       "      <td>Smell, scent, aroma, odor</td>\n",
       "      <td>Beauty Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>HEAD &amp; SHOULDERS</td>\n",
       "      <td>Did you change the making of or fragrance of y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CONTACT_DATE                                   CONTACT_VERBATIM  \\\n",
       "63.0   2018-05-08 00:00:00  Hi, I recently purchased the big bottles of yo...   \n",
       "64.0   2018-05-16 00:00:00  I have been using head and shoulders classic c...   \n",
       "66.0   2018-05-30 00:00:00  I've used Head & Shoulders for years, and for ...   \n",
       "67.0   2018-05-30 00:00:00  I've used Head & Shoulders for years, and for ...   \n",
       "224.0  2018-05-17 00:00:00  Did you change the making of or fragrance of y...   \n",
       "\n",
       "                                  CONTACT_VERBATIM_NOTES  \\\n",
       "63.0                                                       \n",
       "64.0                                                       \n",
       "66.0   question whether anything in the product is co...   \n",
       "67.0   question whether anything in the product is co...   \n",
       "224.0  ant to stop using it but I honestly can’t stan...   \n",
       "\n",
       "                                            PRODUCT_NAME  \\\n",
       "63.0                            Head & Shoulders Shampoo   \n",
       "64.0   Head & Shoulders Shampoo FreshClean Classic Clean   \n",
       "66.0   Head & Shoulders Shampoo Base GreenApple AntiD...   \n",
       "67.0   Head & Shoulders Shampoo Base Apple ADShamCond...   \n",
       "224.0                           Head & Shoulders Shampoo   \n",
       "\n",
       "                                            PRODUCT_PATH  \\\n",
       "63.0                            Head & Shoulders/Shampoo   \n",
       "64.0   Head & Shoulders/Shampoo/Fresh & Clean/Classic...   \n",
       "66.0   Head & Shoulders/Shampoo/Base/Green Apple/Anti...   \n",
       "67.0   Head & Shoulders/Shampoo/Base/Apple/AntiDandru...   \n",
       "224.0                           Head & Shoulders/Shampoo   \n",
       "\n",
       "                COMMENT_CATEGORY            COMMENT_SUBCATEGORY  \\\n",
       "63.0   Product Quality Complaint  Dissatisfied with performance   \n",
       "64.0   Product Quality Complaint             Sensory attributes   \n",
       "66.0   Product Quality Complaint             Sensory attributes   \n",
       "67.0   Product Quality Complaint             Sensory attributes   \n",
       "224.0  Product Quality Complaint             Sensory attributes   \n",
       "\n",
       "                                     COMMENT_DESCRIPTION       SECTOR  \\\n",
       "63.0   Results; did not condition, moisturize as expe...  Beauty Care   \n",
       "64.0                           Smell, scent, aroma, odor  Beauty Care   \n",
       "66.0                           Smell, scent, aroma, odor  Beauty Care   \n",
       "67.0                           Smell, scent, aroma, odor  Beauty Care   \n",
       "224.0                          Smell, scent, aroma, odor  Beauty Care   \n",
       "\n",
       "      SUB_SECTOR   CATEGORY             BRAND  \\\n",
       "63.0   Hair Care  Hair Care  HEAD & SHOULDERS   \n",
       "64.0   Hair Care  Hair Care  HEAD & SHOULDERS   \n",
       "66.0   Hair Care  Hair Care  HEAD & SHOULDERS   \n",
       "67.0   Hair Care  Hair Care  HEAD & SHOULDERS   \n",
       "224.0  Hair Care  Hair Care  HEAD & SHOULDERS   \n",
       "\n",
       "                                   FULL_CONTACT_VERBATIM  \n",
       "63.0   Hi, I recently purchased the big bottles of yo...  \n",
       "64.0   I have been using head and shoulders classic c...  \n",
       "66.0   I've used Head & Shoulders for years, and for ...  \n",
       "67.0   I've used Head & Shoulders for years, and for ...  \n",
       "224.0  Did you change the making of or fragrance of y...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = './data/pqc/'\n",
    "\n",
    "df=1; del df\n",
    "for filename in os.listdir(dirname):\n",
    "    df_tmp = pd.read_csv(os.path.join(dirname, filename), index_col=0, \\\n",
    "        dtype={'CONTACT_VERBATIM':'str', 'CONTACT_VERBATIM_NOTES':'str'})\n",
    "    \n",
    "    # convert brand name to uppercase\n",
    "    df_tmp.BRAND = df_tmp.BRAND.str.upper()\n",
    "    \n",
    "    df_tmp = df_tmp.loc[df_tmp.BRAND==BRAND]\n",
    "    \n",
    "    try:\n",
    "        df = pd.concat([df,df_tmp])\n",
    "    except:\n",
    "        df = df_tmp.copy()\n",
    "\n",
    "df['CONTACT_VERBATIM_NOTES'] = df['CONTACT_VERBATIM_NOTES'].astype(str).apply(lambda x: x if len(x)>4 else '')\n",
    "        \n",
    "df['FULL_CONTACT_VERBATIM'] = df.apply(lambda row: row['CONTACT_VERBATIM']+row['CONTACT_VERBATIM_NOTES'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the text snippets and associated topic; remove duplicates and too short verbatum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep original data\n",
    "df_orig = df.copy()\n",
    "\n",
    "# only keep snippets\n",
    "df = df[['FULL_CONTACT_VERBATIM']].rename(columns = {'FULL_CONTACT_VERBATIM':'text'})\n",
    "\n",
    "# enforce format\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# remove short comments (keep 2nd percentile and higher lenghts)\n",
    "thresh = df['text'].apply(len).quantile(0.02)\n",
    "\n",
    "df = df.loc[df['text'].apply(lambda x: len(x)>=thresh)].\\\n",
    "    drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63.0</th>\n",
       "      <td>Hi, I recently purchased the big bottles of yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64.0</th>\n",
       "      <td>I have been using head and shoulders classic c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>I've used Head &amp; Shoulders for years, and for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224.0</th>\n",
       "      <td>Did you change the making of or fragrance of y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234.0</th>\n",
       "      <td>I purchase some Head &amp; Shoulder Active Sports ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "63.0   Hi, I recently purchased the big bottles of yo...\n",
       "64.0   I have been using head and shoulders classic c...\n",
       "66.0   I've used Head & Shoulders for years, and for ...\n",
       "224.0  Did you change the making of or fragrance of y...\n",
       "234.0  I purchase some Head & Shoulder Active Sports ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)-set(['!','?'])\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess(doc, tags=['NOUN', 'ADJ','VERB','ADV']):\n",
    "    # make entire text lower case\n",
    "    doc = doc.lower()    \n",
    "    \n",
    "    # replace \"n't\" with \" not\" & remove unwanted characters, numbers and symbols\n",
    "    doc = doc.replace(\"n\\'t\", \" not\").replace(\"[^a-zA-Z#]\", \" \")\n",
    "       \n",
    "    # remove stop words\n",
    "    # doc = \" \".join([i for i in doc.split() if i not in stop])\n",
    "    \n",
    "    # remove short words (length < 3)\n",
    "    # doc = \" \".join([r for r in doc.split() if len(r)>2])\n",
    "    \n",
    "    # remove punctuation\n",
    "    # doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "    \n",
    "    # lemmatization\n",
    "    # doc = \" \".join([token.lemma_ for token in nlp(doc) if token.pos_ in tags])\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-Tokenization\n"
     ]
    }
   ],
   "source": [
    "# removes stop words, short words, and punctuation; lowercase and lemmatize all\n",
    "print(' Pre-Tokenization')\n",
    "df['text']        = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Classification - Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "\n",
    "path = Path(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_learner = load_learner(path, \n",
    "                       fname = 'models/topicclassifier_{:}.pkl'.format(BRAND.replace(' ','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = df['text'].apply(lambda row: str(clf_learner.predict(preprocess(row))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_learner = load_learner(path, \n",
    "                       fname = 'models/sentiment_{:}.pkl'.format(BRAND.replace(' ','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['text'].apply(lambda row: str(sent_learner.predict(preprocess(row))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.join(df[['topic','sentiment']]).to_csv('./data/pqc_{:}.csv'.format(BRAND.replace(' ','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: can consider splitting sentences every major punctuation (. ! ?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
