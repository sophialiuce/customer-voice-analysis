{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt, re\n",
    "\n",
    "def main(argv):\n",
    "    inputfile = ''\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv,\"i:\")\n",
    "        # print(opts,args)\n",
    "    except getopt.GetoptError:\n",
    "        print('TopicClassifier.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    \n",
    "    for opt, arg in opts:\n",
    "        if opt == \"-i\":\n",
    "            inputfile = arg\n",
    "    \n",
    "    if len(inputfile)==0:\n",
    "        print('usage: TopicClassifier.py -i <BRAND>')\n",
    "        sys.exit(2)\n",
    "    print('Input BRAND is ', inputfile)\n",
    "    return inputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND      = 'HEAD & SHOULDERS'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BRAND      = main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * # Quick access to NLP functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (from saved verbatim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>verbatum</th>\n",
       "      <th>sentiment_binary</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>retailer</th>\n",
       "      <th>website</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "      <td>Head And Shoulders Smooth &amp; Silky Dandruff Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This shampoo sprays crazy good and it has save...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5/2/2018</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.walmart.com/ip/Head-and-Shoulders-...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The thing I always remember about Head &amp; Shoul...</td>\n",
       "      <td>Head And Shoulders Green Apple Anti-Dandruff S...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My teenaged daughter has been using Head &amp; Sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>9/29/2017</td>\n",
       "      <td>AMZ</td>\n",
       "      <td>https://www.amazon.com/Head-Shoulders-Anti-Dan...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My long, thick, wavy, hair is frequently abuse...</td>\n",
       "      <td>Dove Dermacare Scalp Anti-Dandruff Shampoo Inv...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>To my surprise, Dove DermaCare Scalp Invigorat...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>https://www.walmart.com/ip/Dove-Dermacare-Scal...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From their body sprays, to their deodorant, so...</td>\n",
       "      <td>Dove Dermacare Scalp Anti-Dandruff Shampoo Dry...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I let my boyfriend try this product. He loves ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/27/2017</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.walmart.com/ip/Dove-Dermacare-Scal...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "      <td>Head And Shoulders Dry Scalp Care, Almond Oil,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Its conveniently packaged, but if this bottle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/14/2016</td>\n",
       "      <td>AMZ</td>\n",
       "      <td>https://www.amazon.com/Head-Shoulders-Almond-D...</td>\n",
       "      <td>Spray Application</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             snippet  \\\n",
       "0  This shampoo sprays crazy good and it has save...   \n",
       "1  The thing I always remember about Head & Shoul...   \n",
       "2  My long, thick, wavy, hair is frequently abuse...   \n",
       "3  From their body sprays, to their deodorant, so...   \n",
       "4  Its conveniently packaged, but if this bottle ...   \n",
       "\n",
       "                                             product rating  \\\n",
       "0  Head And Shoulders Smooth & Silky Dandruff Sha...    5.0   \n",
       "1  Head And Shoulders Green Apple Anti-Dandruff S...    5.0   \n",
       "2  Dove Dermacare Scalp Anti-Dandruff Shampoo Inv...    4.0   \n",
       "3  Dove Dermacare Scalp Anti-Dandruff Shampoo Dry...    5.0   \n",
       "4  Head And Shoulders Dry Scalp Care, Almond Oil,...    4.0   \n",
       "\n",
       "                                            verbatum sentiment_binary  \\\n",
       "0  This shampoo sprays crazy good and it has save...                1   \n",
       "1  My teenaged daughter has been using Head & Sho...                1   \n",
       "2  To my surprise, Dove DermaCare Scalp Invigorat...                1   \n",
       "3  I let my boyfriend try this product. He loves ...                1   \n",
       "4  Its conveniently packaged, but if this bottle ...                1   \n",
       "\n",
       "  sentiment       date retailer  \\\n",
       "0  Positive   5/2/2018        -   \n",
       "1  Positive  9/29/2017      AMZ   \n",
       "2  Positive  1/27/2017  WALMART   \n",
       "3  Positive  1/27/2017        -   \n",
       "4  Positive  1/14/2016      AMZ   \n",
       "\n",
       "                                             website              topic  \n",
       "0  https://www.walmart.com/ip/Head-and-Shoulders-...  Spray Application  \n",
       "1  https://www.amazon.com/Head-Shoulders-Anti-Dan...  Spray Application  \n",
       "2  https://www.walmart.com/ip/Dove-Dermacare-Scal...  Spray Application  \n",
       "3  https://www.walmart.com/ip/Dove-Dermacare-Scal...  Spray Application  \n",
       "4  https://www.amazon.com/Head-Shoulders-Almond-D...  Spray Application  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/sample_data.csv', dtype={'verbatum':object})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the text snippets and associated topic; remove duplicates and too short verbatum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep snippets\n",
    "df = df[['snippet','topic']].rename(columns = {'snippet':'text', 'topic':'label'})\n",
    "\n",
    "# enforce format\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# remove short comments (keep 2nd percentile and higher lenghts)\n",
    "thresh = df['text'].apply(len).quantile(0.02)\n",
    "\n",
    "df = df.loc[df['text'].apply(lambda x: len(x)>=thresh)].\\\n",
    "    drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only topics with enough samples\n",
    "df_counts = df.groupby('label').size()\n",
    "df = df.loc[df.label.isin(df_counts[df_counts>df_counts.max()/100].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df = df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup stop words\n",
    "# from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# for word in STOP_WORDS:\n",
    "#     for w in (word, word[0].capitalize(), word.upper()):\n",
    "#         lex = nlp.vocab[w]\n",
    "#         lex.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)-set(['!','?'])\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess(doc, tags=['NOUN', 'ADJ','VERB','ADV']):\n",
    "    # make entire text lower case\n",
    "    doc = doc.lower()    \n",
    "    \n",
    "    # replace \"n't\" with \" not\" & remove unwanted characters, numbers and symbols\n",
    "    doc = doc.replace(\"n\\'t\", \" not\").replace(\"[^a-zA-Z#]\", \" \")\n",
    "       \n",
    "    # remove stop words\n",
    "    # doc = \" \".join([i for i in doc.split() if i not in stop])\n",
    "    \n",
    "    # remove short words (length < 3)\n",
    "    # doc = \" \".join([r for r in doc.split() if len(r)>2])\n",
    "    \n",
    "    # remove punctuation\n",
    "    # doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "    \n",
    "    # lemmatization\n",
    "    # doc = \" \".join([token.lemma_ for token in nlp(doc) if token.pos_ in tags])\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-Tokenization\n"
     ]
    }
   ],
   "source": [
    "# removes stop words, short words, and punctuation; lowercase and lemmatize all\n",
    "print(' Pre-Tokenization')\n",
    "df['text']        = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "\n",
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_trn, seq_tst, y_train, y_test = train_test_split(np.array(range(len(df)))[:,np.newaxis], df['label'],\n",
    "                                                    stratify=df['label'], \n",
    "                                                    test_size=0.25)\n",
    "\n",
    "df_train = df.iloc[seq_trn.squeeze()]\n",
    "df_test  = df.iloc[seq_tst.squeeze()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter for classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "moms = (0.8,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/vocab_{:}.pkl'.format(BRAND.replace(' ','')), 'rb') as handle:\n",
    "    vocab = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path, train_df=df_train, valid_df=df_test, \n",
    "                                      label_cols='label', text_cols='text', \\\n",
    "                                      vocab=vocab, bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute weights for balancing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(df_train['label']),\n",
    "                                                 df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:59 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.779095</td>\n",
       "      <td>2.367620</td>\n",
       "      <td>0.347422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.731513</td>\n",
       "      <td>2.327848</td>\n",
       "      <td>0.349788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.695337</td>\n",
       "      <td>2.286179</td>\n",
       "      <td>0.359008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.693579</td>\n",
       "      <td>2.264864</td>\n",
       "      <td>0.364230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = text_classifier_learner(data_clas, AWD_LSTM)\n",
    "learner.load_encoder('encoder_{:}'.format(BRAND.replace(' ','')))\n",
    "\n",
    "# use class weights\n",
    "loss_weights = torch.FloatTensor(train_weights).cuda()\n",
    "learner.crit = partial(F.cross_entropy, weight=loss_weights)\n",
    "\n",
    "learner.freeze()\n",
    "learner.fit_one_cycle(4, moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:55 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.614967</td>\n",
       "      <td>2.237946</td>\n",
       "      <td>0.369125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.576445</td>\n",
       "      <td>2.202690</td>\n",
       "      <td>0.381854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.565689</td>\n",
       "      <td>2.152503</td>\n",
       "      <td>0.392298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.518616</td>\n",
       "      <td>2.088439</td>\n",
       "      <td>0.407719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.475763</td>\n",
       "      <td>2.023911</td>\n",
       "      <td>0.428198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.424518</td>\n",
       "      <td>2.020624</td>\n",
       "      <td>0.427627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.427917</td>\n",
       "      <td>1.991204</td>\n",
       "      <td>0.436276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.423493</td>\n",
       "      <td>1.992771</td>\n",
       "      <td>0.431870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(8, slice(1e-5,1e-3), moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:00 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.410148</td>\n",
       "      <td>1.975993</td>\n",
       "      <td>0.442232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.454553</td>\n",
       "      <td>1.963489</td>\n",
       "      <td>0.441253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.387548</td>\n",
       "      <td>1.946502</td>\n",
       "      <td>0.446230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.384453</td>\n",
       "      <td>1.932074</td>\n",
       "      <td>0.448678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.freeze()\n",
    "learner.fit_one_cycle(4, moms=moms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learner.predict(preprocess(\"the product left me with itch scalp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learner.predict(preprocess(\"the product did not perform well\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learner.predict(preprocess(\"the rain gave me frizzy hair\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learner.predict(preprocess(\"the cold temperatures affected my hair\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probs, y_correct = learner.get_preds(ds_type = DatasetType.Valid)\n",
    "\n",
    "preds = np.argmax(probs.data.numpy(),axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_correct.data.numpy(), preds)\n",
    "\n",
    "print(classification_report(y_correct.data.numpy(), preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('topicclassifier_{:}'.format(BRAND.replace(' ','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.export(fname = 'models/topicclassifier_{:}.pkl'.format(BRAND.replace(' ','')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
